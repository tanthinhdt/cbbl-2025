{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee09cd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DECISION TREE CLASSIFIER\n",
      "MinMax Scaler: Zeta\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train MCC</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Validation MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.670</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.999</td>\n",
       "      <td>5.670</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.999</td>\n",
       "      <td>7.290</td>\n",
       "      <td>0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.999</td>\n",
       "      <td>5.670</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20254</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.999</td>\n",
       "      <td>7.087</td>\n",
       "      <td>0.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avg.</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.999</td>\n",
       "      <td>6.075</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Seed  Train Loss  Train MCC  Validation Loss  Validation MCC\n",
       "0      7       0.000      1.000            5.670           0.686\n",
       "1     42       0.001      0.999            5.670           0.685\n",
       "2    259       0.001      0.999            7.290           0.598\n",
       "3   2007       0.001      0.999            5.670           0.683\n",
       "4  20254       0.001      0.999            7.087           0.607\n",
       "5   Avg.       0.001      0.999            6.075           0.663"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, log_loss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def evaluate(model_name):\n",
    "\n",
    "    data_dir = \".\"\n",
    "    random_states = [7, 42, 259, 2007, 20254]\n",
    "\n",
    "    metric_dict = {\n",
    "        \"Seed\": [],\n",
    "        \"Train Loss\": [],\n",
    "        \"Train MCC\": [],\n",
    "        \"Validation Loss\": [],\n",
    "        \"Validation MCC\": [],\n",
    "    }\n",
    "\n",
    "    for random_state in random_states:\n",
    "        metric_dict[\"Seed\"].append(random_state)\n",
    "\n",
    "        train_df = pd.read_csv(f\"{data_dir}/train.csv\")\n",
    "\n",
    "        # Encoding the target variable\n",
    "        y_train = train_df[\"Target\"].astype('category').cat.codes.to_numpy()\n",
    "\n",
    "        # Dropping the Target columns from the features\n",
    "        train_feats = train_df.drop(columns=[\"Target\"])\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "\n",
    "        num_cols = train_feats.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "        num_cols.remove(\"ID\")\n",
    "\n",
    "        # STANDARD SCALING\n",
    "        standard_scaler_cols = [\"Zeta\"]\n",
    "        standard_scaler = StandardScaler()\n",
    "\n",
    "        ## Scaling numerical features in the training set\n",
    "        scaled_train_feat = standard_scaler.fit_transform(train_feats[standard_scaler_cols])\n",
    "        scaled_train_df = pd.DataFrame(\n",
    "            scaled_train_feat,\n",
    "            columns=standard_scaler.get_feature_names_out(standard_scaler_cols)\n",
    "        )\n",
    "        train_feats = pd.concat([train_feats.drop(columns=standard_scaler_cols), scaled_train_df], axis=1)\n",
    "\n",
    "\n",
    "        # MIN-MAX SCALING\n",
    "        minmax_scaler_cols = list(set(num_cols) - set(standard_scaler_cols))\n",
    "        minmax_scaler = MinMaxScaler()\n",
    "\n",
    "        ## Scaling numerical features in the training set\n",
    "        scaled_train_feat = minmax_scaler.fit_transform(train_feats[minmax_scaler_cols])\n",
    "        scaled_train_df = pd.DataFrame(\n",
    "            scaled_train_feat,\n",
    "            columns=minmax_scaler.get_feature_names_out(minmax_scaler_cols)\n",
    "        )\n",
    "        train_feats = pd.concat([train_feats.drop(columns=minmax_scaler_cols), scaled_train_df], axis=1)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "\n",
    "        cat_cols = train_feats.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "        label_encoding_cols = [\"Surface_Charge\"]\n",
    "        # label_encoding_cols = []\n",
    "        one_hot_encoding_cols = list(set(cat_cols) - set(label_encoding_cols))\n",
    "\n",
    "        # ONE-HOT ENCODING\n",
    "        one_hot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "        ## Encoding the categorical columns in the training set\n",
    "        encoded_train_features = one_hot_encoder.fit_transform(train_feats[one_hot_encoding_cols])\n",
    "        encoded_df = pd.DataFrame(\n",
    "            encoded_train_features,\n",
    "            columns=one_hot_encoder.get_feature_names_out(one_hot_encoding_cols)\n",
    "        )\n",
    "        train_feats = pd.concat([train_feats.drop(columns=one_hot_encoding_cols), encoded_df], axis=1)\n",
    "\n",
    "\n",
    "        # LABEL ENCODING\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # Encoding the column\n",
    "        train_feats[\"Surface_Charge\"] = label_encoder.fit_transform(train_feats[\"Surface_Charge\"])\n",
    "\n",
    "\n",
    "        # TRAIN TEST SPLIT\n",
    "        X_train = train_feats.drop(columns=[\"ID\"]).to_numpy()\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=random_state)\n",
    "        X_train.shape, y_train.shape, X_val.shape, y_val.shape\n",
    "\n",
    "        # FITTING THE MODEL\n",
    "        model_dict = {\n",
    "            \"Logistic Regression\": LogisticRegression(random_state=random_state),\n",
    "            \"Decision Tree Classifier\": DecisionTreeClassifier(random_state=random_state),\n",
    "            \"Support Vector Classifier\": SVC(random_state=random_state, probability=True),\n",
    "            \"Random Forest Classifier\": RandomForestClassifier(random_state=random_state),\n",
    "            \"Gradient Boosting Classifier\": GradientBoostingClassifier(random_state=random_state),\n",
    "        }\n",
    "        model = model_dict[model_name]\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        train_loss = log_loss(y_train, model.predict_proba(X_train))\n",
    "        metric_dict[\"Train Loss\"].append(round(train_loss, 3))\n",
    "        train_mcc = matthews_corrcoef(y_train, model.predict(X_train))\n",
    "        metric_dict[\"Train MCC\"].append(round(train_mcc, 3))\n",
    "        val_loss = log_loss(y_val, model.predict_proba(X_val))\n",
    "        metric_dict[\"Validation Loss\"].append(round(val_loss, 3))\n",
    "        val_mcc = matthews_corrcoef(y_val, model.predict(X_val))\n",
    "        metric_dict[\"Validation MCC\"].append(round(val_mcc, 3))\n",
    "\n",
    "    metric_dict[\"Seed\"].append(\"Avg.\")\n",
    "    metric_dict[\"Train Loss\"].append(round(np.mean(metric_dict[\"Train Loss\"][:-1]), 3))\n",
    "    metric_dict[\"Train MCC\"].append(round(np.mean(metric_dict[\"Train MCC\"][:-1]), 3))\n",
    "    metric_dict[\"Validation Loss\"].append(round(np.mean(metric_dict[\"Validation Loss\"][:-1]), 3))\n",
    "    metric_dict[\"Validation MCC\"].append(round(np.mean(metric_dict[\"Validation MCC\"][:-1]), 3))\n",
    "\n",
    "    return pd.DataFrame(metric_dict)\n",
    "\n",
    "\n",
    "# model_name = \"Logistic Regression\"\n",
    "model_name = \"Decision Tree Classifier\"\n",
    "# model_name = \"Support Vector Classifier\"\n",
    "# model_name = \"Random Forest Classifier\"\n",
    "# model_name = \"Gradient Boosting Classifier\"\n",
    "print(f\"Model: {model_name.upper()}\")\n",
    "print(\"MinMax Scaler: Zeta\")\n",
    "metric_df = evaluate(model_name)\n",
    "metric_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
